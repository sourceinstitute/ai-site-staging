// http://jekyll.tips/jekyll-casts/jekyll-search-using-lunr-js/

importScripts("/js/lunr.min.js");

var store = {

  
  "/ai-functionality/": {
    "title": "AI Functionality",
    "content": "What Is AI?Welcome to the first lesson of our course on AI.We’ll explain a lot of terms (check out our jargon file for help on that), but always with an eye on how tounderstand AI enough to find business opportunities and act on them. Because,as the book AI for Dummies put it:  “Like the purveyors of the emperor’s new clothes, many of the “hype leaders”are get­ting by because they are depending on the rest of us being too afraidto ask the tough questions or express any doubt.”Or, as Brandon Allgood, CTO at Numerateput it:  “Everyone is being told that they need AI, but few know why – and evenfewer know how to use it.”With that in mind, this course will get you ready to both ask the rightquestions and learn how you can apply AI to practical business cases. Ofcourse the first thing to get to is, just what is AI?In its simplest form, it is the use of algorithms powered by data andprocessing power to draw conclusions. Plenty of other computer programs usealgorithms, that’s how your phone’s calculator works for example, but thebiggest difference here is their application to process large amounts of data.When you ask your calculator to find a square root, you’re inserting a finitenumber of data points and receiving a finite number out. If you told yourcalculator that you, for example, wanted to figure out the best way tocalculate the average number of bedrooms a 100m2 apartment has in Berlin, yourcalculator wouldn’t have the faintest idea how to begin to answer you, eventhough it can handle all of the math involved. The right type of AI algorithmwith the right data, however, could answer just that question.Put another way, AI relies on implied understanding and large amounts of datawhile classic computation uses structured calculations and fixed processes.The next lesson will start to delve into two of the most talked about areaswithin AI: Machine Learning and Deep Learning. We’ll start to explain whateach is, how they fit into the larger world of AI, and what capabilities thesecategories have. The goal of these first few lessons is to get you able tochoose between categories of algorithms given a specific challenge.Machine Learning vs Deep LearningDeep Learning (DL) beyond the buzzwords.(this is an image we borrowed from David Kelner)This chart shows how machine learning is a subset of AI, Deep Learning is asubset within Machine Learning.  *Bear in mind that the timeline in the chart is rough, as these newtechniques evolve over time and aren’t purely the result of “ah hah” moments.Data scientist Yassine Alouini out the distinction most clearly when he wrote:  “Machine learning[1] is the field of makingcomputers smarter and able to learn from the data rather than staticinstructions.  Deep learning[2] is a sub-field of machinelearning focused on** high-level abstracted representation** of data usingmultiple processing layers (thus the deep qualifier).”So is Deep Learning a superior type of Machine Learning which should always bepreferred? Well, Carlos E. Perez warnsabout just that kind of thinking:  “The conclusion that DL is just a better algorithm than SVM [Support vectormachines] or Decision Trees is akin to focusing only on the trees and notseeing the forest.”So DL is both an advanced version of ML and something quite revolutionary inits own right. Its long-term effects look likely to dwarf what other MLalgorithms are capable of. But in the meantime, that doesn’t mean it’s betterfor all business needs (more on that in later lessons). Ultimately, Perezfinds, ironically, that “despite being ignored, DL continues to by hyped”.It’s simultaneously not taken seriously enough and hyped too much and in tooshallow a fashion.The David Kelner article linked to above gave a useful list of the types oftasks DL is suited for:  Recognizing elements in pictures  Translating between languages in real-time  Using speech to control devices (via Apple’s Siri, Google Now; Amazon Alexa and Microsoft Cortana)  Predicting how genetic variation will effect DNA transcription  Analyzing sentiment in customer reviews  Detecting tumours in medical imagesThe limitations are that it requires large datasets, lots of processing power,and is an unexplainable algorithm (more on why that’s important in a laterlesson). So DL is great if you have a more abstract problem to tackle whereyou want an algorithm that can determine how to do the job it’s been assignedlargely on its own, you can afford the raw computing power it needs, you’vegot lots of data to work with, and you don’t need to be able to explainprecisely how it comes to its conclusions.Machine Learning outside of Deep Learning is better suited for more definedtasks like fraud detection, product recommendations, online search, andfinancial trading. But we’ll explore the specific types of algorithms withinMachine Learning and their applications in later lessons.In the next lesson, we’ll explain the difference between unexplainable andexplainable algorithms and, more importantly, why the difference matters whenapplying AI to a use case.Supervised vs UnsupervisedToday’s lesson is a quick one, just explaining another of the commondistinctions between AI algorithms.Karl Morrison summed them up very succinctly onStackExchange:  “[Supervised learning is] to be used when, “I know how to classify thisdata, I just need you (the classifier) to sort it…  [Unsupervised learning is] to be used when, “I have no idea how to classifythis data, can you (the algorithm) create a classifier for me?”…  [Reinforcement learning is] to be used when, “I have no idea how to classifythis data, can you classify this data and I’ll give you a reward if it’scorrect or I’ll punish you if it’s not.”Now let’s look at some examples of each type.Supervised Learning: you show an algorithm pictures of cars and then ask it tolook at a new set pictures and determine whether or not they are pictures ofcars.Unsupervised Learning: you give an algorithm pictures of cars and ask it toinvent categories for the cars and then place those cars into thosecategories.Reinforcement Learning: you give an algorithm pictures of cars and ask it todetermine which cars are “cool” looking. It doesn’t know how to do this so itlearns by making guesses. You tell it whether each guess is correct or not sothe algorithm gradually gets better.But beyond these three basic ideas there’s a lot of math, but this is enoughfor you to know which of these three you’ll need for any given task. When weexplain various ML algorithms, we’ll note whether they’re examples ofsupervised, unsupervised, reinforcement learning, or a combination.If you’d like to unsubscribe, click here. If you have feedback on how we can improve, please reply!:)Generative or DiscriminativeNext, let’s look at the important distinction between generative anddiscriminative algorithms.Discriminative algorithms are therefore better if what you care about is theboundaries between different things instead of how data points are distributedwithin those things. Put another way, generative algorithms care aboutprobabilities, about confidence levels, while discriminative algorithms justclassify things and don’t care whether it’s 51% or 99% certain.Let’s say you want to understand stock performance. If you’d like an algorithmthat can look at a large number of stocks and find interesting patterns, youwant a generative one. If you’d like to, say, look at stocks and determinewhether or not they outperform similar stocks, you’d want a Discriminativealgorithm.Here’s how a StackOverflow usersummarized an example taken from a Stanfordcourse:  suppose we have two classes of animals, elephant(y = 1) and dog(y = 0). Andx is the feature of animals.  Given a training set, an algorithm like logistic regression or theperceptron algorithm (basically) tries to find a straight line–that is, adecision boundary–that separates the elephants and dogs. Then, to classify anew animal as either an elephant or a dog, it checks on which side of thedecision boundary it falls, and makes its prediction accordingly. We callthese discriminative learning algorithm.  Here’s a different approach. First, looking at elephants, we can build amodel of what elephants look like. Then, looking at dogs, we can build aseparate model of what dogs look like. Finally, to classify a new animal, wecan match the new animal against the elephant model, and match it against thedog model, to see whether the new animal looks more like the elephants or morelike the dogs we had seen in the training set. We call these generativelearning algorithm.So when considering which AI algorithms might be suitable for your needs,think about whether the answers you’d like from them would be discriminativeor generative. When we compare all of the AI algorithms in a later lesson,each one will be labeled in one of these categories.ExplainabilityWhen algorithmic decisions need to be explained later, for example decisionsthat need to follow legal compliance, where lives are at stake, or anysituation where ethics are an important component, the explainability ofdifferent approaches must be considered. Some decision-making algorithms canexplain decisions in retrospect, while others can’t. DavidWeinberger compares AlphaGo and Deep Blue, two AI systemsdesigned to play classic games:  “Although AlphaGo has proven itself to be a world class player, it can’tspit out practical maxims from which a human player can learn. The programworks not by developing generalized rules of play – e.g., ‘Never have morethan four sets of unconnected stones on the board’  –  but by analyzing whichplay has the best chance of succeeding given a precise board configuration.”AlphaGo functions through deep learning, a system of layered neurons, morespecifically a Monte Carlo Tree Search (MCTS). With this system, the computerstarts playing games of Go with itself, gradually learning what produces winsand losses. It’s only programmed with the rules of Go, no human gives it a setof criteria for how to develop a strategy other than to win. The number ofneural steps in that process is so massive that there’s no way a human couldfully grasp it. It’s an unexplainable algorithm. We create the basic rules andits designs itself in a way we can’t understand. Or, as Dave Gershgorn putit:  “The way deep neural networks make decisions is often referred to as a‘black box’–while researchers can tune knobs on the outside to vary how themachine functions, its inner workings are granular and difficult to decipher,making the process extremely arduous.”Going back to David Weinberger, the difference between that and Deep Blue isthat:  “In contrast, DeepBlue, thededicated IBM chess-playing computer, has been programmed with some generalprinciples of good play.”Deep Blue is an explainable algorithm. One person can understand the full listof rules it operates under and how it makes any one decision (Kasparov wasfrustrated the team behind it wouldn’t share theprintouts to show its decision making and prove no humanintervened). It’s advantage is its raw computational power. A human can intheory make decisions the way it does, the problem is that it would take anincredible amount of time (an entire lifetime, for example). The same cannotbe said about AlphaGo.In a world increasing concerned about the ethics of AI, having unexplainablealgorithms equals having unexplained ethical systems for making decisions. So,if you’re developing or using an AI system, keep in mind that if you’re goingto need to explain its decision making process and the ethics behind it,explainable AI is probably a better choice.",
    "url": "/ai-functionality/",
    "html": "<div class=\"border-top pt-4 my-4\">\n  <h2>\n    <a href=\"/ai-functionality/\">\n      AI Functionality\n    </a>\n  </h2>\n  <h2 id=\"what-is-ai\">What Is AI?</h2>\n<p>Welcome to the first lesson of our course on AI.</p>\n\n\n</div>\n"
  },

  
  "/business-models/": {
    "title": "Business Models Using AI",
    "content": "Business ModelsFor the last lesson of this two week course, we want you to start thinkingabout how you can apply everything you learned to your business.  “A lot of companies are looking at AI saying: how can I do what I do today,better and faster?That is not the question that you should be asking. Thequestion you should be asking is what can I do today that is fundamentallybetter and different than what I could do yesterday? That’s the real power ofwhat AI can bring to the table”.  -Josh Sutton, Publicis Sapient, from AIBusinessSutton frames how you can think about AI and your business model well. AItools exist which can provide immediate incremental improvements to existingprocesses, but really investing in AI has the potential to take yourcapabilities much farther. Francesco Corea outlines the challenges further inher book Artificial Intelligence and Exponential Technologies: Business ModelsEvolution and New Investment Opportunities:  “It is possible to look at the AI sector as really similar in terms ofbusiness models to the biopharma industry: expensive and long R&amp;D; longinvestment cycle; low-probability enormous returns; concentration of fundingtoward specific phases of development. There are anyway two differencesbetween those two fields: the experimentation phase, that is much faster andpainless for AI, and the (absent) patenting period, which forces AI tocontiniously evolve and use alternative revenue models (e.g., freemiummodel).”With this in mind, it’s not surprising that, as Gayle Sheppard, generalmanager for Saffron Technology (a company within Intel) pointed out at CES2015: the majority of AI is still focused on B2B and not B2C business models.But there are still plenty of applications in both areas. For a bit ofinspiration, we recommend you check out this huge list of both B2B and B2Cbusinesses using AI.After this course, do you feel prepared to discuss, invest in, plan for, etc.,AI? We’d like to know what you feel you’ve learned and where you still feelyou’d like to learn more. We’ll be building more courses in the future so anyfeedback will go directly into developing those.All the best from the Sources team!Will AI Really Lower Labour Costs?Thinking about how AI will impact industries, the idea that AI-basedautomation will push down human labor costs is rampant. But, Carlos Espinal,investor at Seedcamp, used a historical comparison to explain there are otherforces at play than simply lower costs:  “In the case of the 1960s Brasero program [a guest worker program forMexican farm workers to come to the US], it was just that the local worker wasfeeling displaced by the immigrant worker. So, they cancel the Braseroprogram. And the expectation was that by canceling it, all Americans could gettheir jobs back.  But the problem is that the companies had already optimized their modelsaround the costs and margins associated with a lower cheaper labor costs,[making it difficult to return to a model based on higher labour costs].Rather, what happens is the industries adapted themselves and shift the waythat they use their land for produce that was more optimized towards the kindsof cost they could afford.”Carlos compares this situation to customer service outsourcing to cheaper workforces, and then to AI-based automation:  We’ve been exporting customer service to countries where maybe English isn’ta first language, and that became difficult. This was frustrating both forcustomer service representatives and the customers themselves. The cost basisto bring it back to the UK or the US is too high.  We won’t see those jobs return full force, but rather a mass migration tosome kind of automated customer service whereby it’s good enough, and workswith specialists that deal with [particular] situations.We did an in depth analysis of why ending theBrasero program didn’t bring labor costs back up, but the conclusion there wasthat the following factors made the labor market less reactive thananticipated:  How farmers make crop-planting decisions  Existing investment in tractors allowing for low additional capital costs for shifting to new machine-harvestable crops  Advanced in biology allowing leeway for farmers to shift crops and avoid higher labour costs  Strong pressure on farmers to adapt, caused by changes in consumer demand and distributor negotiating powerWhat’s the relationship between lowering human costs and technologicalefficiency in other industries?Usually, technology development is described as adapting solutions for usersor an industry, but Carlos recognized the inverse:  “We might actually have to shape how we look for business, and how we lookfor interactions, to be able to adapt to the needs of AI.”Rather than over-generalise and claim that AI will simply take over bycreating cost-efficiencies and force industries to adapt, what other factorsdo you see when you look at specific industries?How do investment decisions get made – what risks, capital and marginal costsare at play? What external pressures are on the decision makers? Who has thepower? Are existing technology platforms in place that can be easily extendedto use AI? Are other technologies assisting a transition to AI?If you’d like to unsubscribe, click here. If you have feedback on how we can improve, please reply!:)",
    "url": "/business-models/",
    "html": "<div class=\"border-top pt-4 my-4\">\n  <h2>\n    <a href=\"/business-models/\">\n      Business Models Using AI\n    </a>\n  </h2>\n  <h1 id=\"business-models\">Business Models</h1>\n<p>For the last lesson of this two week course, we want you to start thinking\nabout how you can apply everything you learned to your business.</p>\n\n\n</div>\n"
  },

  
  "/common-algorthms/": {
    "title": "Common Algorithms",
    "content": "CategoriesThis is a basic outline of the algorithms we’ll be covering in the next threelessons. They aim at tackling the problem outlined by Montino and Weber above:helping you better compare the capabilities of these AI algorithms.Classification (tell me what category this fits into)Examples of classification tasks would be giving an algorithm medical data andasking it whether the patient has cancer or not. Or, giving an algorithm dataabout your customers and asking it to divide them into categories it willcreate.  Naive Bayes  Support Vector Machine (SVM)  K-Nearest Neighbors  Random Forest  Decision Trees  Artificial Neural Networks  Logistic RegressionRegression (help me predict something based on what I know)Examples of regression tasks would be, say, giving an algorithm historicaldata on traffic patterns and asking it to predict what will happen if youclose a specific road for repairs. Or, entering economic data to ask analgorithm what the effect of a 20% decline in the price of oil on othercommodities will be.  Linear Regression  Support Vector Machine (SVM)  K-Nearest Neighbors  Apriori Algorithm  Random Forest  Decision Trees  Artificial Neural NetworksClustering (tell me what things are alike)Clustering algorithms are best when you don’t just want to know whatcategories data fits into, but how alike or similar they are to everythingelse in that category. For example, you could give a clustering algorithmstock data and ask it to create categories of stocks based on theirperformance. Then, based on what clusters they fit into and where they end upwithin those clusters, you could chose where you’d like to invest.  K Means Clustering  Hierarchical ClusteringClassificationThis lesson breaks down the 6 main AI algorithms which can do this anddiscusses their advantages and disadvantages.  “A good first rule for choosing a method is choose one that you understandvery well.  It’s a theoretical fact that none of these methods are universally anybetter than the other, but I’d argue that perhaps more surprisingly thereisn’t even often a practical difference that is more significant than who isusing the tool.  Barring a deep understanding of any of the methods, trees and their variousensembles (random forests, rotation forests, bagging) are a good place tostart because… they have few free parameters and they’re pretty robust tocommon real-world data pathologies like irrelevant features, missing data,features of different scales, certain kinds of outliers, and they can handlecategorical/numerical data side by side.”  -Rick BarberNaive Bayes AlgorithmYou give the algorithm a series of categories, it takes new data and places itinto one of those categories. However, you do need to tell it when it’scorrect and when it isn’t. The best examples of this are spam filters. Also,just like with spam filters, this isn’t a perfect system and errors willoccur.            Supervised or Unsupervised?      Supervised                  Explainable or unexplainable?      Explainable              Generative or Discriminative?      Generative      Used for: document classification and sentiment analysisSpecific Use Cases: spam filters, disease prediction, document classification,sentiment analysis.Requirements: A medium to large data set, less than 100,000 samples generally,several attributes to analyze, conditionally independent attributes, abalanced data set.Support Vector Machine (SVM)This algorithm classifies data by drawing a line between them, maximizing thedistance between the data and the line. It tends to be very good at notoverfitting (when an algorithm gets really good at its test data and bad atpredicting other thigns, check out our Jargon file for more on that). So,it’s great at accurately classifying new data based on its training set. Theflip side of this is that it doesn’t perform well with huge data sets or ifthe classes you’re separating your data into overlap. An example might betrying to analyze news stories and determine whether they are positive ornegative based on the words used.            Supervised or Unsupervised?      Supervised                  Explainable or unexplainable?      Explainable              Generative or Discriminative?      Discriminative      Used for: Efficiently classifying data and not overfitting based on thetraining data.Specific Use Cases: Data science libraries, facial expression classification,text categorization, speech recognition.Requirements: As mentioned, you don’t want your data set too large. Fordocuments, one example showed performance slowly began todecrease once it analyzedmore than 1,000 documents. You also shouldn’t have overlapping classes. It’sbetter with binary classification overall. You also can’t attribute meaning toits decisions because they are unexplainable.K-Nearest NeighborsConsidered the simplest classificationalgorithm, it classifies data points based on theclassification of nearby data points. Because of its simplicity, it’s veryfast and the data is very easy to interpret, though its predictive power ismore average. But be careful and scale yourdata(so you don’t, for example, have some data on a 1-5 scale while other data ison a 0-100 scale, they should all be on the same scale), otherwise thisalgorithm can really lead you astray.Supervised or Unsupervised? | Supervised—|—Explainable or unexplainable? |ExplainableGenerative or Discriminative? | GenerativeUsed for: simple classification tasksSpecific Use Cases: Gene expression, understanding protein structures andinteractions, basic classification of items like, say flowers, based on theircharacteristics.Requirements: Can be done with &lt;100,000 samples, data should be able to berepresented on a plane, your data is scalable.Decision TreesThis algorithm is designed to help you handle uncertainty in classifyingthings. More specifically, they help you better understand how any one changeaffects other factors in classifying things, kind of a big pictureperspective. It’s also good if your data isincomplete.Supervised or Unsupervised? | Supervised—|—Explainable or unexplainable? | ExplainableGenerative or Discriminative? | DiscriminativeUsed for: weighing complex situations with multiple decision-making steps,each of which affects what future options are availableSpecific Use Cases: option pricing, classifying loan applicants,Requirements: Should be relatively small, the larger it gets the less accurateand usable it gets. Relies on your expectations, which could be wrong. In thisway, these are very human and fallible versions of AI.Random ForestCreates a series of decision trees with small random variations and calculateseach one. Then, it polls the results to come up with an overall prediction. Soit has all the same requirements as a regular decision tree algorithm becauseit begins with the same type of data. The big difference is that it helps toprevent overfitting, which can be a problem with a single decision tree.Supervised or Unsupervised? | Supervised—|—Explainable or unexplainable? | ExplainableGenerative or Discriminative? | DiscriminativeUsed for: weighing complex situations with multiple decision-making steps,each of which affects what future options are available where you want toprevent overfittingSpecific Use Cases: classifying loan applications, predicting mechanicalfailures, predict the onset of chronic disease.Requirements: Super easy to use, lots of open source options,  overfittingisn’t really an issue here. Other than that, it has all the same advantages ofa regular decision tree.Artificial Neural Networks (ANNs)(Sometimes called Neural Networks, though this technically refers to a broadercategory including things like deep belief networks.) This is probably themost famous type of classification algorithm. It broadly mimics the structureof the human brain by layering artificial neurons. Each layer chooses a factorit determines to be important and uses it to make choices to give betteroutputs. This structure makes ANNs very flexible.            Supervised or Unsupervised?      Can be either                  Explainable or unexplainable?      Unexplainable              Generative or Discriminative?      Can be either      Used for: When you need a system to figure out how to classify things anddon’t care how the system does it.Specific Use Cases: Character recognition, image compression, stock marketprediction, application decisions (universities, bank loans, etc.), and manymore.Requirements: Difficult to set up, needs thousands of cycles to train itself,difficult to troubleshoot when issues arise, but extremely powerful when itworks (extremetech has some excellent examples of what it cando).Logistic RegressionDon’t be fooled by the name, this may be “logistic regression” but it’s aclassification algorithm, not a regression one. It just happens to useregression techniques to do its classification. It looks at a bunch ofvariables and predicts the probability of a data point falling into a specificcategory based on them.Supervised or Unsupervised? |Supervised—|—Explainable or unexplainable? | ExplainableGenerative or Discriminative? | DiscriminativeUsed for: Answering whether a set of predictors can accurately categorizedata.Specific Use Cases: Image Segmentation and Categorization, Geographic ImageProcessing, Handwriting recognition, Healthcare predictions.Requirements: You shouldn’t have outliers, also your variables shouldn’t behighly correlated with each other.RegressionNow we’re going to break down all the algorithms you can use for regressionand the characteristics of each. Regression itself is all about predictingfuture data based on past data.  “A good first rule for choosing a method is choose one that you understandvery well.  It’s a theoretical fact that none of these methods are universally anybetter than the other, but I’d argue that perhaps more surprisingly thereisn’t even often a practical difference that is more significant than who isusing the tool.  Barring a deep understanding of any of the methods, trees and their variousensembles (random forests, rotation forests, bagging) are a good place tostart because… they have few free parameters and they’re pretty robust tocommon real-world data pathologies like irrelevant features, missing data,features of different scales, certain kinds of outliers, and they can handlecategorical/numerical data side by side.”  -Rick BarberLinear RegressionThis algorithm shows the relationship between two variables and how changes inone affect the other. But this is not based on individual cases, it’s based onan overall conclusions the algorithm draws from the data.Supervised or Unsupervised? | Unsupervised—|—Explainable or unexplainable? | ExplainableGenerative or Discriminative? |DiscriminativeUsed for: Showing how a change in one variable will affect another variableSpecific Use Cases: Sales estimations, risk assessment, traffic predictionRequirements: Not many, famously easy to use and explain. It’s also very fast.There are risks of test error and bias affecting your results.Support Vector Machine Algorithm (SVMs)This algorithm classifies data by drawing a hyperplane (a line or plane)between them. It maximizes the distance between the data and thehyperplane(s), which means that it tends to be very good at not overfitting.It usually does this to classify the data, but when used for regression thetrajectory of the hyperplane itself is the regression. As a result, it’s greatat accurately classifying new data based on its training set. The flip side ofthis is that it doesn’t perform well with huge data sets or if the classesyou’re separating your data into overlapSupervised or Unsupervised? | Supervised—|—Explainable or unexplainable? |UnexplainableGenerative or Discriminative? | DiscriminativeUsed for: Efficiently classifying data and not overfitting based on thetraining data.Specific Use Cases:  Stock market and other financialforecasting (comparing relativeperformance of stocks relative to others in the same sector), time seriesforecasting, automatic currencycontrol.Requirements: As mentioned, you don’t want your data set too large. Fordocuments, one example showed the ability to generalize decreasing after 1,000documents slowly began todecrease. You also shouldn’thave overlapping classes.K-Nearest NeighborsWhen it’s regression, it estimates the value of a point based on the value ofnearby points instead of its classification based on nearby points. It’sconsidered the simplest classificationalgorithm. Because of its simplicity, it’s very fastand the data is very easy to interpret, though its predictive power is moreaverage. But be careful and scale yourdataso it’s directly comparable, otherwise this algorithm can really lead youastray.Supervised or Unsupervised? | Supervised—|—Explainable or unexplainable? |ExplainableGenerative or Discriminative? | GenerativeUsed for: Estimating continuous variables by distance from each other.Specific Use Cases: Predicting housing prices, loan amounts, and otherfinancial indicators.Requirements: Can be done with &lt;100,000 samples, none of your independentvariables should have a lot of variance or interact with each other (theyshould be relatively standard and distinct).Decision TreesWhen the variable you’re trying to predict is continuous (meaning it has aninfinite number of possible values, and not just, say, 1-100), a decision treeregression works well. It’s also good if your data isincomplete, fast, and accurate.Supervised or Unsupervised? | Supervised—|—Explainable or unexplainable? | ExplainableGenerative or Discriminative? | DiscriminativeUsed for: Quickly and accurately predicting values.Specific Use Cases: Predicting the price of a consumer goodRequirements: Should be relatively small, the larger it gets the less accurateand usable it gets. Relies on your expectations, which could be wrong. In thisway, these are very human and fallible versions of AI.Random ForestsCreates a series of decision trees with small random variations and calculateseach one. Then, it polls the results to come up with an overall prediction. Soit has all the same requirements as a regular decision tree algorithm becauseit begins with the same type of data.Supervised or Unsupervised? | Supervised—|—Explainable or unexplainable? | ExplainableGenerative or Discriminative? | DiscriminativeUsed for: weighing a number of variables to make predictions.Specific Use Cases: Predicting income, crop yields, test scores, or homeprices.Requirements: Super easy to use, lots of open source options,  overfittingisn’t really an issue here. Other than that, it has all the same advantages ofa regular decision treeArtificial Neural NetworksThis is probably the most famous type of classification algorithm. It broadlymimics the structure of the human brain by layering artificial neurons. Eachlayer chooses a factor it determines to be important and uses it to makechoices to give better outputs. This structure makes ANNs very flexible.            Supervised or Unsupervised?      Can be either                  Explainable or unexplainable?      Unexplainable              Generative or Discriminative?      Can be either      Used for: When you need a system to figure out how to estimate things anddon’t care how the system does it.Specific Use Cases: Predicting prices, crop yields, weather, test scores, andmuch more.Requirements: Considerable skill is required to build this type of network, itneeds thousands of cycles to train itself, it’s difficult to troubleshoot whenissues arise. However, it is extremely powerful when it works.ClusteringFinally, this lesson will break down the two main clustering algorithms.Remember, clustering algorithms are best when you don’t just want to know whatcategories data fits into, but how alike or similar they are to everythingelse in that category. For example, you could give a clustering algorithmstock data and ask it to create categories of stocks based on theirperformance. Then, based on what clusters they fit into and where they end upwithin those clusters, you could chose where you’d like to invest. This isdifferent from classification, which will only put a label on the data andwon’t tell you anything about how different the data within a single categoryis.K Means ClusteringBetter when you already know what clusters you want to divide your data into.It’s a very simple algorithm to classify numerical data intoclusters.            Supervised or Unsupervised?      Unsupervised                  Explainable or unexplainable?      Explainable              Generative or Discriminative?      Discriminative      Used for: Dividing data into clusters (where their spacial relationships areimportant) instead of just classes (in which case you would use a classifieralgorithm).Specific Use Cases: Some financial analysis, astronomy, agriculture,microprocessor design, and geostatistics.Requirements: You have to know how many clusters you want. The data has to benumerical.Hierarchical ClusteringThis clustering algorithm creates a hierarchical structure of clusters anddoes not require you to pre-specify the number of clusters you want. It’sdeterministic, meaning if the input remains the same, the output will alwaysremain the same. It’s also slower to run than K-Means.            Supervised or Unsupervised?      Unsupervised                  Explainable or unexplainable?      Explainable              Generative or Discriminative?      Discriminative      Used for: Creating ranked clusters.Specific Use Cases: Search engine queries, image classification (but only partof the process), and document classificationRequirements: Your data has to be numerical.",
    "url": "/common-algorthms/",
    "html": "<div class=\"border-top pt-4 my-4\">\n  <h2>\n    <a href=\"/common-algorthms/\">\n      Common Algorithms\n    </a>\n  </h2>\n  <h1 id=\"categories\">Categories</h1>\n<p>This is a basic outline of the algorithms we’ll be covering in the next three\nlessons. They aim at tackling the problem outlined by Montino and Weber above:\nhelping you better compare the capabilities of these AI algorithms.</p>\n\n\n</div>\n"
  },

  
  "/practicalities/": {
    "title": "Practicalities",
    "content": "Do you need to build your own AI?First, a clarification of the term ‘off the shelf’  “There’s virtually no such thing as off the shelf AI. There are plenty ofgreat APIs which you could call off the shelf, for example. But, very oftenyou run into the need to adapt and build upon them to make anything more thanan MVP. It’s similar to big data - everyone wants to claim they’re off theshelf and that’s how it’s pitched but in reality it often needs a good amountof custom work.  -Boyan Benev, Founder of GainIMAndreessen Horowitz breaks down the overlaps between API, Library, andSDK, but when discussing“off the shelf” AI, these three concepts are included within that umbrellaterm (which is a bit problematic, but that’s how people are using it thesedays). Also within that term are end-user software products like ProjectDreamcatcher. Thesereally are products you can pick up and start using without the need tointegrate or customize them for your needs. So, looking broadly at the methodsof using AI that fall within the “off the shelf” umbrella, here are some rulesof thumb:‘Off the Shelf’ Advantages:  The cost is known (and probably less than a custom solution, though not 100% of the time).  The capabilities are known.  Off the shelf products are becoming more flexible (look to the Google example below)  Less development time.Off the Shelf Disadvantages:  “The downside of commercial software is that they are in most cases completeblack boxes to the users and even to the company’s engineers. These packagesare developed as single-sell products which address one specific topic or useand could prove to be unusable if the situation and the environment changes.Or the company has to pay for an adoption with additional extensions throughadd-ons or customization contracts.”  -Ralf Montino and Christian Weber, from Integration of Practice-OrientedKnowledge Technology: Trends and Prospectives  There is often a lack of explainability  Not very adaptable (yet, but again this is changing)  You lose potential opportunities for patenting and licensing your own AI product.Google is also the elephant in the room when it comes to off the shelf AIalgorithms. As of their 2017 I/O event, they’re working on positioningthemselves as leaders in providing the building blocks on which others canbuild off the shelf tools:  “What Google is really talking about is creating the software and the chipsthat the entire AI infrastructure then is going to be built on… Google istrying to create the foundation for that… What also Google is doing isdesigning these systems where basically they’re giving companies the buildingblocks. And then the companies can use those building blocks to create theirown AI products. It’s almost the way that right now it’s so easy to create awebsite, so different than what it was say 15, 20 years ago. So this is whatGoogle is seeing… creating an AI product will be that simple, but it will allbe tied into the Google system.”  -Anna Szymanski on theSlate MoneyPodcastBut ultimately, whether you’re looking to build a custom AI algorithms or useoff-the-shelf options, knowledge of how to evaluate them is critical (and amajor reason for the creation of this course):  “In the end, the real downside [of off the shelf AI solutions] is… the gapbetween the availability of complex AI methods and techniques and the missingknowledge to judge them for buying as a product.”  -Ralf Montino and Christian Weber, from Integration of Practice-OrientedKnowledge Technology: Trends andProspectivesAt this point, their AI is even beating their own engineers are creating moreAI. So, consider the benefits of custom vs off the shelf andkeep an eye on what Google is doing. The next lesson will delve into the costside of this question in more detail.If you’d like to unsubscribe, click here. If you have feedback on how we can improve, please reply!:)Investment costsIn the last lesson we mentioned that using off the shelf solutions for AI hasthe advantage of giving you fixed costs, capabilities, and development times.But to understand the importance of those factors, they should be compared tothe costs and risks of developing your own AI. This lesson delves into thatquestion, though to be clear, these are only a few examples to give you abroad idea of what costs could be.Let’s look at an increasingly common example: chatbots.  “Take the simplest option of each of the 3 variables above [What is theindustry vertical, What level of interaction, and What action capabilities?]and that’s going to be around 0K. Now to the other extreme and you’re talking50K and up”  -Gam DiasSo between the cheapest and most expensive price points is an 830% difference.Another software development firm estimates ,000 to 2,240 for a simpler chatbotwhich isn’t, say, designed to represent a major brand with the high standardsthat come with that.But what about implementing AI algorithms to analyze data? Krassimir (Casey)Paskalev suggestion focused on how this can be done quickly and efficientlywith a data scientist:  “Technically, the fastest cheapest easiest way [to extract conclusions fromdata] is that a data scientist has to sign an NDA and run with it for a day ora week. That will be cheap, that scientist will have lots of interestinginsights and they can capture 90% of the business value that way.”  But, “If you can’t afford a full-time data scientist or don’t think you haveenough work for them, hiring a consultant is another possible route. But asyou might expect, quality varies. As with all consultants, avoid those who mayappear too good to be true.”  -Brandon Allgood, CTO at NumerateOn Upwork, for example, freelance data scientists charge between 6 and 00 anhour. They cite an average project cost of 00, though that canobviously vary a lot depending on the complexity of the algorithm and how muchtraining it needs (you can use our lessons comparing them to get a feel forthis).Finally, for developing a full blown custom-built AI solution for somethinglike augmented reality, supply chain optimization, historic performanceanalysis, or content categorization, the costs are much higher.AI.Works, a custom AI development company, breaksdown its estimates like this:Estimates only go so far, as once you get toward the later stages ofdevelopment, there are too many extraneous factors to fully predict costs. Butthis overview should give you a general idea of what you can expect in termsof developing chatbots, custom AI solutions, and simple data analysisalgorithms.The next two lessons will look at gathering and uses data for AI solutions.If you’d like to unsubscribe, click here. If you have feedback on how we can improve, please reply!:)Tuning AlgorithmsFor Yavor Stoychev, learningto tune algorithms for eCommerce applications was a trial by fire in thetrenches at Amazon. While he eventually brought those hard-won insights to co-founding his own eCommerce company, Perpetto,getting there required learning that tuning algorithms is a bigger and morecomplex job than he realized.  “All I found out while we were building this predictor at Amazon is that …it’s not really a plug-and-play thing. You don’t just develop something andlaunch it in the first iteration. It takes a lot of trial and error to figureout what data is actually important. In a machine learning algorithm, youprovide it with a certain input and it gives you an answer to a question youhave. What happens is you have to figure out what data is relevant. This turnsout to be a fairly difficult problem and it takes a lot of trials to get itright.  What we found out… is that the type of delivery that the customer chose atcheckout… [is] not really an important determining factor for whether theywill place a second order or not. We had certain assumptions that were false.For example, one was the shipping method, one was the categories and whetherthey purchase from the same category more often than not. We had certain datathat we thought was going to important but it wasn’t. And we ended up swappingit, trying something else, and just going through a lot of iterations of trialand error to get this right.  You never get it 100% perfect. You get closer and closer and closer and atone point it just becomes good enough and you’re satisfied. Because it’s not adeterministic system [IE, this is or is not a car]. It’s a probabilisticsystem [IE, how likely is is that a person will buy jeans after they buyshoes]…”How did Yavor apply those lessons learned when he left Amazon to co-foundPerpetto?  “We started building machine learning technology using a framework calledPrediction IO, which was really good for data scientists and for anybodyreally who wanted to get something off the ground quickly. Because they hadthe infrastructure in place so you could just one click install it. It willset up all the necessary services for you and then you can download templatesfor it on the internet and run them and see how they work. Customize them, runthem again. So it was a really good playground where you could experiment andcustomize templates so that it fits your need and then launch them…. Itreally helped us get off the ground quickly because we had templates forcollaborative filtering, we had three of them. We just went ahead, we playedwith them, we customized them, and we launched them within a month I wouldsay… That month was full of weekends and weekend nights playing with machinelearning technology. We were just experimenting.”So, understanding that experimentation was going to be necessary, Yavor choseto work with a more flexible platform the second time around. Building in theassumption that extensive tuning, tweaking, and testing was going to benecessary, even for a framework as usable as Prediction IO, allowed Perpettoto get its AI systems working very quickly.If you’d like to unsubscribe, click here. If you have feedback on how we can improve, please reply!:)More Data or Better Data?This lesson aims to give you a general framework for thinking about data andAI by raising a fundamental question about quantity versus quality.Norman Winarsky, vice president of Ventures at SRIInternational, co-founder and former board member ofSiri,said at an AI conference in April 2017 that:  “Between a better algorithm and data, choose data. It’s the key in thefuture. It’s the gold rush, like oil in the Middle East.”Or, as Google’s Research Director Peter Norvig put it:  “We don’t have better algorithms. We just have more data.”With this in mind, where should your focus be, on getting better data or moredata?Start with the types of algorithms available and their data requirements. Fora bit more detail, here’s a chart from Scilearn.So focus on the specifics of your situation, but are there general rules ofthumb when it comes to data?Let’s take the example, mentioned in a previous lesson, of the Support VectorMachine Algorithm. When applied to regression tasks, it will actually performworse with a larger data set. Though this is an exception, comparing it tothis famous chart from Banko andBrill on natural languagedisambiguation:So who’s right?Xavier Amatriain, theleading Engineer at Quora, made the point that overgeneralization arerife  when it comes to applying data to AI. Some claim thatmore data always beats a better algorithm while others claim that betterquality data will always beat more data. But there are always exceptions.  “There’s a tendency for businesses to rush in and start collecting all ofthe data we can. However, it’s possible that what you’re collecting is thewrong data (or incomplete data) because you’re simply collecting data fordata’s sake. Instead, figure out what questions you want AI to answer and workyour way back to identifying what data will prove valuable.  At my firm, in the beginning stages of any project we try to understand whatspecific challenges we’ll face. Every project is different and comes withdifferent risks. Based on those risks, we can determine which models we’llneed to build in order to reduce this risk. Then, from the models we’veoutlined to build, our team will search existing databases for related data aswell as determine which data we should be collecting/producing throughout theproject to further guide our efforts.”  -Brandon Allgood, CTO at NumerateThe point to pull from this is that you first need to narrow in on what yourspecific needs are, find the algorithms you can use, then ask whether more orbetter data will make a substantial difference. If you want to know more aboutthe type of data needed for your algorithm, you can hire a datascientist to answer your questions.In the next lesson, we’ll add to what was outlined in this lesson bydiscussing historical vs real time data.If you’d like to unsubscribe, click here. If you have feedback on how we can improve, please reply!:)",
    "url": "/practicalities/",
    "html": "<div class=\"border-top pt-4 my-4\">\n  <h2>\n    <a href=\"/practicalities/\">\n      Practicalities\n    </a>\n  </h2>\n  <h1 id=\"do-you-need-to-build-your-own-ai\">Do you need to build your own AI?</h1>\n\n\n</div>\n"
  }

};

// Initialize lunr
var idx = lunr(function () {
  this.ref('url');
  this.field('title', { boost: 10 });
  this.field('content');
});

// Add content to index
for(var id in store) {
  idx.add(store[id]);
}

onmessage = function (e) {
  var results = idx.search(e.data).map(function(result) {
    return store[result.ref].html;
  });
  postMessage(results);
}
